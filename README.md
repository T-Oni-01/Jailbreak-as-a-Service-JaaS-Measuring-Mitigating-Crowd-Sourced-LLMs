# Jailbreak-as-a-Service-JaaS-Measuring-Mitigating-Crowd-Sourced-LLMs

I offer the first systematic study of Jailbreak-as-a-
Service (JaaS) attacks, where adversarial prompts are crowd-
sourced and distributed through underground platforms. This
research introduces: (1) a hierarchical taxonomy of 6 jail-
break techniques with 15 subcategories, modeled after MITRE
ATT&CK; (2) a feature-based mathematical framework for
jailbreak classification; and (3) an active learning system that
reduces false positives through human feedback. By analyzing nu-
merous real-world prompts from sources such as JailbreakChat,
GitHub, Discord, and Reddit, I demonstrate how JaaS platforms
operationalize LLM vulnerabilities at scale. The proposed mitiga-
tion pipeline combines semantic analysis, adversarial robustness
testing, and a novel confidence-based review system, aimed at
outperforming existing methods in detecting emerging attack
patterns.

<img width="785" height="263" alt="Draw_IO Taxonomy" src="https://github.com/user-attachments/assets/0d0e1ea6-e888-4879-a963-496ff17b9aa6" />

<img width="959" height="502" alt="Database of prompts" src="https://github.com/user-attachments/assets/1facad75-95e4-4ed2-8b9a-f25bfd700e54" />

<img width="959" height="503" alt="1000 promts" src="https://github.com/user-attachments/assets/de806186-abba-4e3e-a932-00066f275459" />
<img width="959" height="539" alt="Initial Code Run Results" src="https://github.com/user-attachments/assets/529d0fc2-b712-4e81-a9db-ceb5fa033972" />


<img width="959" height="518" alt="Results Prompt2" src="https://github.com/user-attachments/assets/0938091c-e026-4f7e-8be5-285cfa3cc8bb" />
